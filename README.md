## 修改日志

### 2022/1/8

开始编译前向神经网络。一开始尝试将常数值写进神经元，即给神经元加入恒为1的常量，但是在进行权重更新时，十分不便，遂放弃，更改为在激活函数中加入常数值，目前还未完成。

### 2022/1/10

一月九号将神经网络的预测和训练过程都写完了，但是预测结果十分糟糕，在测试集上的正确率也只有0.1左右，可以认为是训练失败，通过分界面可以看到在训练集上的效果也完全没有分开。

#### 原因包括以下几点：

1、一开始想要将激活函数中的 theta 和 gama 替换成在输入层和隐藏层的常数神经元，但是在权重更新过程中就需要不断地增加删减矩阵的某一列，十分麻烦，于是放弃这种方式，改用显现的将 theta 和 gama 求出来。

2、没有对数据进行归一化，导致 softmax 函数和 sigmoid 函数发生溢出问题。

3、更新权重的函数在传递过程中出现顺序错误。

4、**学习率设置**

在一开始的训练过程中，学习率设置的是0.1，出现的结果就是完全训练不出结果，将学习率改为0.01后学习效果瞬间变好，具体原因还没有想明白。

5、**网络结构设计**

网络结构一开始采用的是 2-4-4，后来采用 2-3-4 发现效果能够更好一些，具体原因未知。

6、样本特征太少，只有两个。

#### 现在要解决的问题包括：

1、怎么设计网络结构？

2、怎么调整学习率？

3、对于特征很少的情况怎么解决？

### 2022/1/11

对于 GMM6 数据集，采用隐藏层数量为64，学习率为0.001后，得到目前最好的效果。

对于三分类问题隐藏层设置不宜过多，调整为 8 个后分类效果明显得到改善

![image-20220111203656912](C:\Users\syr11\AppData\Roaming\Typora\typora-user-images\image-20220111203656912.png)



GMM 中出现溢出现象

numpy.dot 在处理一维矩阵的叉乘时存在问题

神经网络升维以后：![image-20220111224839196](D:\桑养\杂项\ANN+128+3000+0.001五倍交叉验证GMM6)

继续优化神经网络，编写实现混合高斯分布的贝叶斯模型，实现五折交叉验证，实现了维度的提高。

对于样本集 GMM8 中存在的样本空间分布紧密的现象，线性模型不具有良好的分类效果，正确率都位于0.875以下，可以认为对于右上角的两类分类完全失败。但这也正是线性分类器无法解决的 XOR 问题。

多层神经网络作为非线性模型，本应该在GMM8上具有较好的分类能力，但是我的实现并没有得到这样的结果，可能是代码的编写存在问题，或者样本的特征太少导致的.
